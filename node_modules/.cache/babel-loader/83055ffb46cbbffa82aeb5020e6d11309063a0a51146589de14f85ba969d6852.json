{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\Dad\\\\Documents\\\\ai-react\\\\src\\\\App.js\",\n  _s = $RefreshSig$();\nimport React from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { useState, useEffect } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst Dictaphone = () => {\n  _s();\n  const [response, setResponse] = useState('');\n  const [voice, setVoice] = useState('');\n  const [listen, setListen] = useState(false);\n  useEffect(() => {\n    console.log(voice);\n  }, [voice]);\n  const {\n    transcript,\n    listening,\n    resetTranscript,\n    browserSupportsSpeechRecognition\n  } = useSpeechRecognition();\n  if (!browserSupportsSpeechRecognition) {\n    return /*#__PURE__*/_jsxDEV(\"span\", {\n      children: \"Browser doesn't support speech recognition.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 23,\n      columnNumber: 12\n    }, this);\n  }\n  const callGPT = async () => {\n    const prompt = '';\n    const request = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": \"Bearer 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\"\n      },\n      body: JSON.stringify({\n        \"model\": \"gpt-3.5-turbo\",\n        \"max_tokens\": 500,\n        \"messages\": [{\n          \"role\": \"system\",\n          \"content\": prompt\n        }, {\n          \"role\": \"user\",\n          \"content\": transcript\n        }]\n      })\n    });\n    const data = await request.json();\n    const responseText = data.choices && data.choices.length > 0 ? data.choices[0].message.content : \"No response from God.\";\n    setResponse(responseText);\n    let audio = new Audio(`http://localhost:3001/speech?text=${responseText}`);\n    audio.play();\n    console.log(responseText);\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"p\", {\n      children: [\"Microphone: \", listening ? 'on' : 'off']\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 63,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: () => {\n        SpeechRecognition.startListening();\n        setListen(true);\n      },\n      children: \"Start\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 64,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: () => {\n        SpeechRecognition.stopListening();\n        setListen(false);\n        setVoice(transcript);\n      },\n      children: \"Stop\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 68,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: resetTranscript,\n      children: \"Reset\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 73,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: callGPT,\n      children: \"Ask\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 74,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      children: listen ? 'Listening...' : 'Not Listening'\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 75,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        backgroundColor: 'light-grey'\n      },\n      children: response ? response : 'No response'\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 76,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 62,\n    columnNumber: 5\n  }, this);\n};\n_s(Dictaphone, \"ozR3+Id14BgDMg9XR9gNJPZBxF4=\", false, function () {\n  return [useSpeechRecognition];\n});\n_c = Dictaphone;\nexport default Dictaphone;\nvar _c;\n$RefreshReg$(_c, \"Dictaphone\");","map":{"version":3,"names":["React","SpeechRecognition","useSpeechRecognition","useState","useEffect","jsxDEV","_jsxDEV","Dictaphone","_s","response","setResponse","voice","setVoice","listen","setListen","console","log","transcript","listening","resetTranscript","browserSupportsSpeechRecognition","children","fileName","_jsxFileName","lineNumber","columnNumber","callGPT","prompt","request","fetch","method","headers","body","JSON","stringify","data","json","responseText","choices","length","message","content","audio","Audio","play","onClick","startListening","stopListening","style","backgroundColor","_c","$RefreshReg$"],"sources":["C:/Users/Dad/Documents/ai-react/src/App.js"],"sourcesContent":["import React from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { useState, useEffect } from 'react';\n\nconst Dictaphone = () => {\n  const [response, setResponse] = useState('');\n  const [voice, setVoice] = useState('');\n  const [listen, setListen] = useState(false);\n\n  useEffect(() => {\n    console.log(voice)\n  }, [voice])\n\n\n  const {\n    transcript,\n    listening,\n    resetTranscript,\n    browserSupportsSpeechRecognition\n  } = useSpeechRecognition();\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>Browser doesn't support speech recognition.</span>;\n  }\n\n  const callGPT = async () => {\n\n    const prompt = '';\n\n    const request = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": \"Bearer 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\"\n      },\n      body: JSON.stringify({\n        \"model\": \"gpt-3.5-turbo\",\n        \"max_tokens\": 500,\n        \"messages\": [\n          {\n            \"role\": \"system\",\n            \"content\": prompt\n          },\n          {\n            \"role\": \"user\",\n            \"content\": transcript\n          }\n        ]\n      })\n    })\n    const data = await request.json();\n    const responseText = data.choices && data.choices.length > 0 ? data.choices[0].message.content : \"No response from God.\";\n    setResponse(responseText);\n    let audio = new Audio(`http://localhost:3001/speech?text=${responseText}`);\n    audio.play();\n    console.log(responseText)\n  }\n\n\n\n  return (\n    <div>\n      <p>Microphone: {listening ? 'on' : 'off'}</p>\n      <button onClick={() => {\n        SpeechRecognition.startListening();\n        setListen(true);\n      }}>Start</button>\n      <button onClick={() => {\n        SpeechRecognition.stopListening();\n        setListen(false);\n        setVoice(transcript);\n      }}>Stop</button>\n      <button onClick={resetTranscript}>Reset</button>\n      <button onClick={callGPT}>Ask</button>\n      <div>{listen ? 'Listening...' : 'Not Listening'}</div>\n      <div style={{ backgroundColor: 'light-grey' }}>{response ? response : 'No response'}</div>\n    </div>\n  );\n}\n\n\nexport default Dictaphone;"],"mappings":";;AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAOC,iBAAiB,IAAIC,oBAAoB,QAAQ,0BAA0B;AAClF,SAASC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE5C,MAAMC,UAAU,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACvB,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGP,QAAQ,CAAC,EAAE,CAAC;EAC5C,MAAM,CAACQ,KAAK,EAAEC,QAAQ,CAAC,GAAGT,QAAQ,CAAC,EAAE,CAAC;EACtC,MAAM,CAACU,MAAM,EAAEC,SAAS,CAAC,GAAGX,QAAQ,CAAC,KAAK,CAAC;EAE3CC,SAAS,CAAC,MAAM;IACdW,OAAO,CAACC,GAAG,CAACL,KAAK,CAAC;EACpB,CAAC,EAAE,CAACA,KAAK,CAAC,CAAC;EAGX,MAAM;IACJM,UAAU;IACVC,SAAS;IACTC,eAAe;IACfC;EACF,CAAC,GAAGlB,oBAAoB,CAAC,CAAC;EAE1B,IAAI,CAACkB,gCAAgC,EAAE;IACrC,oBAAOd,OAAA;MAAAe,QAAA,EAAM;IAA2C;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC;EACjE;EAEA,MAAMC,OAAO,GAAG,MAAAA,CAAA,KAAY;IAE1B,MAAMC,MAAM,GAAG,EAAE;IAEjB,MAAMC,OAAO,GAAG,MAAMC,KAAK,CAAC,4CAA4C,EAAE;MACxEC,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,cAAc,EAAE,kBAAkB;QAClC,eAAe,EAAE;MACnB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnB,OAAO,EAAE,eAAe;QACxB,YAAY,EAAE,GAAG;QACjB,UAAU,EAAE,CACV;UACE,MAAM,EAAE,QAAQ;UAChB,SAAS,EAAEP;QACb,CAAC,EACD;UACE,MAAM,EAAE,MAAM;UACd,SAAS,EAAEV;QACb,CAAC;MAEL,CAAC;IACH,CAAC,CAAC;IACF,MAAMkB,IAAI,GAAG,MAAMP,OAAO,CAACQ,IAAI,CAAC,CAAC;IACjC,MAAMC,YAAY,GAAGF,IAAI,CAACG,OAAO,IAAIH,IAAI,CAACG,OAAO,CAACC,MAAM,GAAG,CAAC,GAAGJ,IAAI,CAACG,OAAO,CAAC,CAAC,CAAC,CAACE,OAAO,CAACC,OAAO,GAAG,uBAAuB;IACxH/B,WAAW,CAAC2B,YAAY,CAAC;IACzB,IAAIK,KAAK,GAAG,IAAIC,KAAK,CAAE,qCAAoCN,YAAa,EAAC,CAAC;IAC1EK,KAAK,CAACE,IAAI,CAAC,CAAC;IACZ7B,OAAO,CAACC,GAAG,CAACqB,YAAY,CAAC;EAC3B,CAAC;EAID,oBACE/B,OAAA;IAAAe,QAAA,gBACEf,OAAA;MAAAe,QAAA,GAAG,cAAY,EAACH,SAAS,GAAG,IAAI,GAAG,KAAK;IAAA;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAC7CnB,OAAA;MAAQuC,OAAO,EAAEA,CAAA,KAAM;QACrB5C,iBAAiB,CAAC6C,cAAc,CAAC,CAAC;QAClChC,SAAS,CAAC,IAAI,CAAC;MACjB,CAAE;MAAAO,QAAA,EAAC;IAAK;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eACjBnB,OAAA;MAAQuC,OAAO,EAAEA,CAAA,KAAM;QACrB5C,iBAAiB,CAAC8C,aAAa,CAAC,CAAC;QACjCjC,SAAS,CAAC,KAAK,CAAC;QAChBF,QAAQ,CAACK,UAAU,CAAC;MACtB,CAAE;MAAAI,QAAA,EAAC;IAAI;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eAChBnB,OAAA;MAAQuC,OAAO,EAAE1B,eAAgB;MAAAE,QAAA,EAAC;IAAK;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eAChDnB,OAAA;MAAQuC,OAAO,EAAEnB,OAAQ;MAAAL,QAAA,EAAC;IAAG;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eACtCnB,OAAA;MAAAe,QAAA,EAAMR,MAAM,GAAG,cAAc,GAAG;IAAe;MAAAS,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC,eACtDnB,OAAA;MAAK0C,KAAK,EAAE;QAAEC,eAAe,EAAE;MAAa,CAAE;MAAA5B,QAAA,EAAEZ,QAAQ,GAAGA,QAAQ,GAAG;IAAa;MAAAa,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACvF,CAAC;AAEV,CAAC;AAAAjB,EAAA,CA1EKD,UAAU;EAAA,QAeVL,oBAAoB;AAAA;AAAAgD,EAAA,GAfpB3C,UAAU;AA6EhB,eAAeA,UAAU;AAAC,IAAA2C,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}