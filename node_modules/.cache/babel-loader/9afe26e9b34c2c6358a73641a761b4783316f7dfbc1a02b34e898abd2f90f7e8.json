{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\Dad\\\\Documents\\\\ai-react\\\\src\\\\App.js\",\n  _s = $RefreshSig$();\nimport React from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { useState, useEffect } from 'react';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst Dictaphone = () => {\n  _s();\n  const [response, setResponse] = useState('');\n  const [voice, setVoice] = useState('');\n  const [input, setInput] = useState(null);\n  useEffect(() => {\n    console.log(voice);\n  }, [voice]);\n  const {\n    transcript,\n    listening,\n    resetTranscript,\n    browserSupportsSpeechRecognition\n  } = useSpeechRecognition();\n  if (!browserSupportsSpeechRecognition) {\n    return /*#__PURE__*/_jsxDEV(\"span\", {\n      children: \"Browser doesn't support speech recognition.\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 23,\n      columnNumber: 12\n    }, this);\n  }\n  const callGPT = async () => {\n    const prompt = '';\n    const request = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": \"Bearer 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\"\n      },\n      body: JSON.stringify({\n        \"model\": \"gpt-3.5-turbo\",\n        \"max_tokens\": 500,\n        \"messages\": [{\n          \"role\": \"system\",\n          \"content\": prompt\n        }, {\n          \"role\": \"user\",\n          \"content\": input ? input : transcript\n        }]\n      })\n    });\n    const data = await request.json();\n    const responseText = data.choices && data.choices.length > 0 ? data.choices[0].message.content : \"No response from God.\";\n    setResponse(responseText);\n    let audio = new Audio(`http://localhost:3001/speech?text=${responseText}`);\n    audio.play();\n    console.log(responseText);\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    children: [/*#__PURE__*/_jsxDEV(\"p\", {\n      style: {\n        color: listening ? 'green' : 'red'\n      },\n      children: [\"Microphone: \", listening ? 'on' : 'off']\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 63,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"textarea\", {}, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 64,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: () => {\n        SpeechRecognition.startListening();\n      },\n      children: \"Record\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 65,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: () => {\n        SpeechRecognition.stopListening();\n        setVoice(transcript);\n      },\n      children: \"Stop\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 68,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: () => {\n        resetTranscript();\n        setResponse(null);\n      },\n      children: \"Reset\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 72,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n      onClick: callGPT,\n      children: \"Ask\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 76,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      style: {\n        backgroundColor: 'rgb(191, 186, 186)'\n      },\n      children: response ? response : 'No response'\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 77,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 62,\n    columnNumber: 5\n  }, this);\n};\n_s(Dictaphone, \"hcSGo1EQohvOFUfDTINbe2eMseU=\", false, function () {\n  return [useSpeechRecognition];\n});\n_c = Dictaphone;\nexport default Dictaphone;\nvar _c;\n$RefreshReg$(_c, \"Dictaphone\");","map":{"version":3,"names":["React","SpeechRecognition","useSpeechRecognition","useState","useEffect","jsxDEV","_jsxDEV","Dictaphone","_s","response","setResponse","voice","setVoice","input","setInput","console","log","transcript","listening","resetTranscript","browserSupportsSpeechRecognition","children","fileName","_jsxFileName","lineNumber","columnNumber","callGPT","prompt","request","fetch","method","headers","body","JSON","stringify","data","json","responseText","choices","length","message","content","audio","Audio","play","style","color","onClick","startListening","stopListening","backgroundColor","_c","$RefreshReg$"],"sources":["C:/Users/Dad/Documents/ai-react/src/App.js"],"sourcesContent":["import React from 'react';\nimport SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\nimport { useState, useEffect } from 'react';\n\nconst Dictaphone = () => {\n  const [response, setResponse] = useState('');\n  const [voice, setVoice] = useState('');\n  const [input, setInput] = useState(null);\n\n  useEffect(() => {\n    console.log(voice)\n  }, [voice])\n\n\n  const {\n    transcript,\n    listening,\n    resetTranscript,\n    browserSupportsSpeechRecognition\n  } = useSpeechRecognition();\n\n  if (!browserSupportsSpeechRecognition) {\n    return <span>Browser doesn't support speech recognition.</span>;\n  }\n\n  const callGPT = async () => {\n\n    const prompt = '';\n\n    const request = await fetch(\"https://api.openai.com/v1/chat/completions\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": \"Bearer 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\"\n      },\n      body: JSON.stringify({\n        \"model\": \"gpt-3.5-turbo\",\n        \"max_tokens\": 500,\n        \"messages\": [\n          {\n            \"role\": \"system\",\n            \"content\": prompt\n          },\n          {\n            \"role\": \"user\",\n            \"content\": input ? input : transcript\n          }\n        ]\n      })\n    })\n    const data = await request.json();\n    const responseText = data.choices && data.choices.length > 0 ? data.choices[0].message.content : \"No response from God.\";\n    setResponse(responseText);\n    let audio = new Audio(`http://localhost:3001/speech?text=${responseText}`);\n    audio.play();\n    console.log(responseText)\n  }\n\n\n\n  return (\n    <div>\n      <p style={{ color: listening ? 'green' : 'red' }}>Microphone: {listening ? 'on' : 'off'}</p>\n      <textarea></textarea>\n      <button onClick={() => {\n        SpeechRecognition.startListening();\n      }}>Record</button>\n      <button onClick={() => {\n        SpeechRecognition.stopListening();\n        setVoice(transcript);\n      }}>Stop</button>\n      <button onClick={() => {\n        resetTranscript();\n        setResponse(null);\n      }}>Reset</button>\n      <button onClick={callGPT}>Ask</button>\n      <div style={{ backgroundColor: 'rgb(191, 186, 186)' }}>{response ? response : 'No response'}</div>\n    </div>\n  );\n}\n\n\nexport default Dictaphone;"],"mappings":";;AAAA,OAAOA,KAAK,MAAM,OAAO;AACzB,OAAOC,iBAAiB,IAAIC,oBAAoB,QAAQ,0BAA0B;AAClF,SAASC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAE5C,MAAMC,UAAU,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACvB,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGP,QAAQ,CAAC,EAAE,CAAC;EAC5C,MAAM,CAACQ,KAAK,EAAEC,QAAQ,CAAC,GAAGT,QAAQ,CAAC,EAAE,CAAC;EACtC,MAAM,CAACU,KAAK,EAAEC,QAAQ,CAAC,GAAGX,QAAQ,CAAC,IAAI,CAAC;EAExCC,SAAS,CAAC,MAAM;IACdW,OAAO,CAACC,GAAG,CAACL,KAAK,CAAC;EACpB,CAAC,EAAE,CAACA,KAAK,CAAC,CAAC;EAGX,MAAM;IACJM,UAAU;IACVC,SAAS;IACTC,eAAe;IACfC;EACF,CAAC,GAAGlB,oBAAoB,CAAC,CAAC;EAE1B,IAAI,CAACkB,gCAAgC,EAAE;IACrC,oBAAOd,OAAA;MAAAe,QAAA,EAAM;IAA2C;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC;EACjE;EAEA,MAAMC,OAAO,GAAG,MAAAA,CAAA,KAAY;IAE1B,MAAMC,MAAM,GAAG,EAAE;IAEjB,MAAMC,OAAO,GAAG,MAAMC,KAAK,CAAC,4CAA4C,EAAE;MACxEC,MAAM,EAAE,MAAM;MACdC,OAAO,EAAE;QACP,cAAc,EAAE,kBAAkB;QAClC,eAAe,EAAE;MACnB,CAAC;MACDC,IAAI,EAAEC,IAAI,CAACC,SAAS,CAAC;QACnB,OAAO,EAAE,eAAe;QACxB,YAAY,EAAE,GAAG;QACjB,UAAU,EAAE,CACV;UACE,MAAM,EAAE,QAAQ;UAChB,SAAS,EAAEP;QACb,CAAC,EACD;UACE,MAAM,EAAE,MAAM;UACd,SAAS,EAAEd,KAAK,GAAGA,KAAK,GAAGI;QAC7B,CAAC;MAEL,CAAC;IACH,CAAC,CAAC;IACF,MAAMkB,IAAI,GAAG,MAAMP,OAAO,CAACQ,IAAI,CAAC,CAAC;IACjC,MAAMC,YAAY,GAAGF,IAAI,CAACG,OAAO,IAAIH,IAAI,CAACG,OAAO,CAACC,MAAM,GAAG,CAAC,GAAGJ,IAAI,CAACG,OAAO,CAAC,CAAC,CAAC,CAACE,OAAO,CAACC,OAAO,GAAG,uBAAuB;IACxH/B,WAAW,CAAC2B,YAAY,CAAC;IACzB,IAAIK,KAAK,GAAG,IAAIC,KAAK,CAAE,qCAAoCN,YAAa,EAAC,CAAC;IAC1EK,KAAK,CAACE,IAAI,CAAC,CAAC;IACZ7B,OAAO,CAACC,GAAG,CAACqB,YAAY,CAAC;EAC3B,CAAC;EAID,oBACE/B,OAAA;IAAAe,QAAA,gBACEf,OAAA;MAAGuC,KAAK,EAAE;QAAEC,KAAK,EAAE5B,SAAS,GAAG,OAAO,GAAG;MAAM,CAAE;MAAAG,QAAA,GAAC,cAAY,EAACH,SAAS,GAAG,IAAI,GAAG,KAAK;IAAA;MAAAI,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAI,CAAC,eAC5FnB,OAAA;MAAAgB,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAoB,CAAC,eACrBnB,OAAA;MAAQyC,OAAO,EAAEA,CAAA,KAAM;QACrB9C,iBAAiB,CAAC+C,cAAc,CAAC,CAAC;MACpC,CAAE;MAAA3B,QAAA,EAAC;IAAM;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eAClBnB,OAAA;MAAQyC,OAAO,EAAEA,CAAA,KAAM;QACrB9C,iBAAiB,CAACgD,aAAa,CAAC,CAAC;QACjCrC,QAAQ,CAACK,UAAU,CAAC;MACtB,CAAE;MAAAI,QAAA,EAAC;IAAI;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eAChBnB,OAAA;MAAQyC,OAAO,EAAEA,CAAA,KAAM;QACrB5B,eAAe,CAAC,CAAC;QACjBT,WAAW,CAAC,IAAI,CAAC;MACnB,CAAE;MAAAW,QAAA,EAAC;IAAK;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eACjBnB,OAAA;MAAQyC,OAAO,EAAErB,OAAQ;MAAAL,QAAA,EAAC;IAAG;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAQ,CAAC,eACtCnB,OAAA;MAAKuC,KAAK,EAAE;QAAEK,eAAe,EAAE;MAAqB,CAAE;MAAA7B,QAAA,EAAEZ,QAAQ,GAAGA,QAAQ,GAAG;IAAa;MAAAa,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAM,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OAC/F,CAAC;AAEV,CAAC;AAAAjB,EAAA,CA3EKD,UAAU;EAAA,QAeVL,oBAAoB;AAAA;AAAAiD,EAAA,GAfpB5C,UAAU;AA8EhB,eAAeA,UAAU;AAAC,IAAA4C,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}